
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>litekmeans</title><meta name="generator" content="MATLAB 8.6"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-03-19"><meta name="DC.source" content="litekmeans.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><pre class="codeinput"><span class="keyword">function</span> [label, center, bCon, sumD, D] = litekmeans(X, k, varargin)
<span class="comment">%LITEKMEANS K-means clustering, accelerated by matlab matrix operations.</span>
<span class="comment">%</span>
<span class="comment">%   label = LITEKMEANS(X, K) partitions the points in the N-by-P data matrix</span>
<span class="comment">%   X into K clusters.  This partition minimizes the sum, over all</span>
<span class="comment">%   clusters, of the within-cluster sums of point-to-cluster-centroid</span>
<span class="comment">%   distances.  Rows of X correspond to points, columns correspond to</span>
<span class="comment">%   variables.  KMEANS returns an N-by-1 vector label containing the</span>
<span class="comment">%   cluster indices of each point.</span>
<span class="comment">%</span>
<span class="comment">%   [label, center] = LITEKMEANS(X, K) returns the K cluster centroid</span>
<span class="comment">%   locations in the K-by-P matrix center.</span>
<span class="comment">%</span>
<span class="comment">%   [label, center, bCon] = LITEKMEANS(X, K) returns the bool value bCon to</span>
<span class="comment">%   indicate whether the iteration is converged.</span>
<span class="comment">%</span>
<span class="comment">%   [label, center, bCon, SUMD] = LITEKMEANS(X, K) returns the</span>
<span class="comment">%   within-cluster sums of point-to-centroid distances in the 1-by-K vector</span>
<span class="comment">%   sumD.</span>
<span class="comment">%</span>
<span class="comment">%   [label, center, bCon, SUMD, D] = LITEKMEANS(X, K) returns</span>
<span class="comment">%   distances from each point to every centroid in the N-by-K matrix D.</span>
<span class="comment">%</span>
<span class="comment">%   [ ... ] = LITEKMEANS(..., 'PARAM1',val1, 'PARAM2',val2, ...) specifies</span>
<span class="comment">%   optional parameter name/value pairs to control the iterative algorithm</span>
<span class="comment">%   used by KMEANS.  Parameters are:</span>
<span class="comment">%</span>
<span class="comment">%   'Distance' - Distance measure, in P-dimensional space, that KMEANS</span>
<span class="comment">%      should minimize with respect to.  Choices are:</span>
<span class="comment">%            {'sqEuclidean'} - Squared Euclidean distance (the default)</span>
<span class="comment">%             'cosine'       - One minus the cosine of the included angle</span>
<span class="comment">%                              between points (treated as vectors). Each</span>
<span class="comment">%                              row of X SHOULD be normalized to unit. If</span>
<span class="comment">%                              the intial center matrix is provided, it</span>
<span class="comment">%                              SHOULD also be normalized.</span>
<span class="comment">%</span>
<span class="comment">%   'Start' - Method used to choose initial cluster centroid positions,</span>
<span class="comment">%      sometimes known as "seeds".  Choices are:</span>
<span class="comment">%         {'sample'}  - Select K observations from X at random (the default)</span>
<span class="comment">%          'cluster' - Perform preliminary clustering phase on random 10%</span>
<span class="comment">%                      subsample of X.  This preliminary phase is itself</span>
<span class="comment">%                      initialized using 'sample'. An additional parameter</span>
<span class="comment">%                      clusterMaxIter can be used to control the maximum</span>
<span class="comment">%                      number of iterations in each preliminary clustering</span>
<span class="comment">%                      problem.</span>
<span class="comment">%           matrix   - A K-by-P matrix of starting locations; or a K-by-1</span>
<span class="comment">%                      indicate vector indicating which K points in X</span>
<span class="comment">%                      should be used as the initial center.  In this case,</span>
<span class="comment">%                      you can pass in [] for K, and KMEANS infers K from</span>
<span class="comment">%                      the first dimension of the matrix.</span>
<span class="comment">%</span>
<span class="comment">%   'MaxIter'    - Maximum number of iterations allowed.  Default is 100.</span>
<span class="comment">%</span>
<span class="comment">%   'Replicates' - Number of times to repeat the clustering, each with a</span>
<span class="comment">%                  new set of initial centroids. Default is 1. If the</span>
<span class="comment">%                  initial centroids are provided, the replicate will be</span>
<span class="comment">%                  automatically set to be 1.</span>
<span class="comment">%</span>
<span class="comment">% 'clusterMaxIter' - Only useful when 'Start' is 'cluster'. Maximum number</span>
<span class="comment">%                    of iterations of the preliminary clustering phase.</span>
<span class="comment">%                    Default is 10.</span>
<span class="comment">%</span>
<span class="comment">%</span>
<span class="comment">%    Examples:</span>
<span class="comment">%</span>
<span class="comment">%       fea = rand(500,10);</span>
<span class="comment">%       [label, center] = litekmeans(fea, 5, 'MaxIter', 50);</span>
<span class="comment">%</span>
<span class="comment">%       fea = rand(500,10);</span>
<span class="comment">%       [label, center] = litekmeans(fea, 5, 'MaxIter', 50, 'Replicates', 10);</span>
<span class="comment">%</span>
<span class="comment">%       fea = rand(500,10);</span>
<span class="comment">%       [label, center, bCon, sumD, D] = litekmeans(fea, 5, 'MaxIter', 50);</span>
<span class="comment">%       TSD = sum(sumD);</span>
<span class="comment">%</span>
<span class="comment">%       fea = rand(500,10);</span>
<span class="comment">%       initcenter = rand(5,10);</span>
<span class="comment">%       [label, center] = litekmeans(fea, 5, 'MaxIter', 50, 'Start', initcenter);</span>
<span class="comment">%</span>
<span class="comment">%       fea = rand(500,10);</span>
<span class="comment">%       idx=randperm(500);</span>
<span class="comment">%       [label, center] = litekmeans(fea, 5, 'MaxIter', 50, 'Start', idx(1:5));</span>
<span class="comment">%</span>
<span class="comment">%</span>
<span class="comment">%   See also KMEANS</span>
<span class="comment">%</span>
<span class="comment">%    [Cite] Deng Cai, "Litekmeans: the fastest matlab implementation of</span>
<span class="comment">%           kmeans," Available at:</span>
<span class="comment">%           http://www.zjucadcg.cn/dengcai/Data/Clustering.html, 2011.</span>
<span class="comment">%</span>
<span class="comment">%   version 2.0 --December/2011</span>
<span class="comment">%   version 1.0 --November/2011</span>
<span class="comment">%</span>
<span class="comment">%   Written by Deng Cai (dengcai AT gmail.com)</span>


<span class="keyword">if</span> nargin &lt; 2
    error(<span class="string">'litekmeans:TooFewInputs'</span>,<span class="string">'At least two input arguments required.'</span>);
<span class="keyword">end</span>

[n, p] = size(X);


pnames = {   <span class="string">'distance'</span> <span class="string">'start'</span>   <span class="string">'maxiter'</span>  <span class="string">'replicates'</span> <span class="string">'onlinephase'</span> <span class="string">'clustermaxiter'</span>};
dflts =  {<span class="string">'sqeuclidean'</span> <span class="string">'sample'</span>       []        []        <span class="string">'off'</span>              []        };
[eid,errmsg,distance,start,maxit,reps,online,clustermaxit] = getargs(pnames, dflts, varargin{:});
<span class="keyword">if</span> ~isempty(eid)
    error(sprintf(<span class="string">'litekmeans:%s'</span>,eid),errmsg);
<span class="keyword">end</span>

<span class="keyword">if</span> ischar(distance)
    distNames = {<span class="string">'sqeuclidean'</span>,<span class="string">'cosine'</span>};
    j = strcmpi(distance, distNames);
    j = find(j);
    <span class="keyword">if</span> length(j) &gt; 1
        error(<span class="string">'litekmeans:AmbiguousDistance'</span>, <span class="keyword">...</span>
            <span class="string">'Ambiguous ''Distance'' parameter value:  %s.'</span>, distance);
    <span class="keyword">elseif</span> isempty(j)
        error(<span class="string">'litekmeans:UnknownDistance'</span>, <span class="keyword">...</span>
            <span class="string">'Unknown ''Distance'' parameter value:  %s.'</span>, distance);
    <span class="keyword">end</span>
    distance = distNames{j};
<span class="keyword">else</span>
    error(<span class="string">'litekmeans:InvalidDistance'</span>, <span class="keyword">...</span>
        <span class="string">'The ''Distance'' parameter value must be a string.'</span>);
<span class="keyword">end</span>


center = [];
<span class="keyword">if</span> ischar(start)
    startNames = {<span class="string">'sample'</span>,<span class="string">'cluster'</span>};
    j = find(strncmpi(start,startNames,length(start)));
    <span class="keyword">if</span> length(j) &gt; 1
        error(message(<span class="string">'litekmeans:AmbiguousStart'</span>, start));
    <span class="keyword">elseif</span> isempty(j)
        error(message(<span class="string">'litekmeans:UnknownStart'</span>, start));
    <span class="keyword">elseif</span> isempty(k)
        error(<span class="string">'litekmeans:MissingK'</span>, <span class="keyword">...</span>
            <span class="string">'You must specify the number of clusters, K.'</span>);
    <span class="keyword">end</span>
    <span class="keyword">if</span> j == 2
        <span class="keyword">if</span> floor(.1*n) &lt; 5*k
            j = 1;
        <span class="keyword">end</span>
    <span class="keyword">end</span>
    start = startNames{j};
<span class="keyword">elseif</span> isnumeric(start)
    <span class="keyword">if</span> size(start,2) == p
        center = start;
    <span class="keyword">elseif</span> (size(start,2) == 1 || size(start,1) == 1)
        center = X(start,:);
    <span class="keyword">else</span>
        error(<span class="string">'litekmeans:MisshapedStart'</span>, <span class="keyword">...</span>
            <span class="string">'The ''Start'' matrix must have the same number of columns as X.'</span>);
    <span class="keyword">end</span>
    <span class="keyword">if</span> isempty(k)
        k = size(center,1);
    <span class="keyword">elseif</span> (k ~= size(center,1))
        error(<span class="string">'litekmeans:MisshapedStart'</span>, <span class="keyword">...</span>
            <span class="string">'The ''Start'' matrix must have K rows.'</span>);
    <span class="keyword">end</span>
    start = <span class="string">'numeric'</span>;
<span class="keyword">else</span>
    error(<span class="string">'litekmeans:InvalidStart'</span>, <span class="keyword">...</span>
        <span class="string">'The ''Start'' parameter value must be a string or a numeric matrix or array.'</span>);
<span class="keyword">end</span>

<span class="comment">% The maximum iteration number is default 100</span>
<span class="keyword">if</span> isempty(maxit)
    maxit = 100;
<span class="keyword">end</span>

<span class="comment">% The maximum iteration number for preliminary clustering phase on random</span>
<span class="comment">% 10% subsamples is default 10</span>
<span class="keyword">if</span> isempty(clustermaxit)
    clustermaxit = 10;
<span class="keyword">end</span>


<span class="comment">% Assume one replicate</span>
<span class="keyword">if</span> isempty(reps) || ~isempty(center)
    reps = 1;
<span class="keyword">end</span>

<span class="keyword">if</span> ~(isscalar(k) &amp;&amp; isnumeric(k) &amp;&amp; isreal(k) &amp;&amp; k &gt; 0 &amp;&amp; (round(k)==k))
    error(<span class="string">'litekmeans:InvalidK'</span>, <span class="keyword">...</span>
        <span class="string">'X must be a positive integer value.'</span>);
<span class="keyword">elseif</span> n &lt; k
    error(<span class="string">'litekmeans:TooManyClusters'</span>, <span class="keyword">...</span>
        <span class="string">'X must have more rows than the number of clusters.'</span>);
<span class="keyword">end</span>


bestlabel = [];
sumD = zeros(1,k);
bCon = false;

<span class="keyword">for</span> t=1:reps
    <span class="keyword">switch</span> start
        <span class="keyword">case</span> <span class="string">'sample'</span>
            center = X(randsample(n,k),:);
        <span class="keyword">case</span> <span class="string">'cluster'</span>
            Xsubset = X(randsample(n,floor(.1*n)),:);
            [dump, center] = litekmeans(Xsubset, k, varargin{:}, <span class="string">'start'</span>,<span class="string">'sample'</span>, <span class="string">'replicates'</span>,1 ,<span class="string">'MaxIter'</span>,clustermaxit);
        <span class="keyword">case</span> <span class="string">'numeric'</span>
    <span class="keyword">end</span>

    last = 0;label=1;
    it=0;

    <span class="keyword">switch</span> distance
        <span class="keyword">case</span> <span class="string">'sqeuclidean'</span>
            <span class="keyword">while</span> any(label ~= last) &amp;&amp; it&lt;maxit
                last = label;

                bb = full(sum(center.*center,2)');
                ab = full(X*center');
                D = bb(ones(1,n),:) - 2*ab;

                [val,label] = min(D,[],2); <span class="comment">% assign samples to the nearest centers</span>
                ll = unique(label);
                <span class="keyword">if</span> length(ll) &lt; k
                    <span class="comment">%disp([num2str(k-length(ll)),' clusters dropped at iter ',num2str(it)]);</span>
                    missCluster = 1:k;
                    missCluster(ll) = [];
                    missNum = length(missCluster);

                    aa = sum(X.*X,2);
                    val = aa + val;
                    [dump,idx] = sort(val,1,<span class="string">'descend'</span>);
                    label(idx(1:missNum)) = missCluster;
                <span class="keyword">end</span>
                E = sparse(1:n,label,1,n,k,n);  <span class="comment">% transform label into indicator matrix</span>
                center = full((E*spdiags(1./sum(E,1)',0,k,k))'*X);    <span class="comment">% compute center of each cluster</span>
                it=it+1;
            <span class="keyword">end</span>
            <span class="keyword">if</span> it&lt;maxit
                bCon = true;
            <span class="keyword">end</span>
            <span class="keyword">if</span> isempty(bestlabel)
                bestlabel = label;
                bestcenter = center;
                <span class="keyword">if</span> reps&gt;1
                    <span class="keyword">if</span> it&gt;=maxit
                        aa = full(sum(X.*X,2));
                        bb = full(sum(center.*center,2));
                        ab = full(X*center');
                        D = bsxfun(@plus,aa,bb') - 2*ab;
                        D(D&lt;0) = 0;
                    <span class="keyword">else</span>
                        aa = full(sum(X.*X,2));
                        D = aa(:,ones(1,k)) + D;
                        D(D&lt;0) = 0;
                    <span class="keyword">end</span>
                    D = sqrt(D);
                    <span class="keyword">for</span> j = 1:k
                        sumD(j) = sum(D(label==j,j));
                    <span class="keyword">end</span>
                    bestsumD = sumD;
                    bestD = D;
                <span class="keyword">end</span>
            <span class="keyword">else</span>
                <span class="keyword">if</span> it&gt;=maxit
                    aa = full(sum(X.*X,2));
                    bb = full(sum(center.*center,2));
                    ab = full(X*center');
                    D = bsxfun(@plus,aa,bb') - 2*ab;
                    D(D&lt;0) = 0;
                <span class="keyword">else</span>
                    aa = full(sum(X.*X,2));
                    D = aa(:,ones(1,k)) + D;
                    D(D&lt;0) = 0;
                <span class="keyword">end</span>
                D = sqrt(D);
                <span class="keyword">for</span> j = 1:k
                    sumD(j) = sum(D(label==j,j));
                <span class="keyword">end</span>
                <span class="keyword">if</span> sum(sumD) &lt; sum(bestsumD)
                    bestlabel = label;
                    bestcenter = center;
                    bestsumD = sumD;
                    bestD = D;
                <span class="keyword">end</span>
            <span class="keyword">end</span>
        <span class="keyword">case</span> <span class="string">'cosine'</span>
            <span class="keyword">while</span> any(label ~= last) &amp;&amp; it&lt;maxit
                last = label;
                W=full(X*center');
                [val,label] = max(W,[],2); <span class="comment">% assign samples to the nearest centers</span>
                ll = unique(label);
                <span class="keyword">if</span> length(ll) &lt; k
                    missCluster = 1:k;
                    missCluster(ll) = [];
                    missNum = length(missCluster);
                    [dump,idx] = sort(val);
                    label(idx(1:missNum)) = missCluster;
                <span class="keyword">end</span>
                E = sparse(1:n,label,1,n,k,n);  <span class="comment">% transform label into indicator matrix</span>
                center = full((E*spdiags(1./sum(E,1)',0,k,k))'*X);    <span class="comment">% compute center of each cluster</span>
                centernorm = sqrt(sum(center.^2, 2));
                center = center ./ centernorm(:,ones(1,p));
                it=it+1;
            <span class="keyword">end</span>
            <span class="keyword">if</span> it&lt;maxit
                bCon = true;
            <span class="keyword">end</span>
            <span class="keyword">if</span> isempty(bestlabel)
                bestlabel = label;
                bestcenter = center;
                <span class="keyword">if</span> reps&gt;1
                    <span class="keyword">if</span> any(label ~= last)
                        W=full(X*center');
                    <span class="keyword">end</span>
                    D = 1-W;
                    <span class="keyword">for</span> j = 1:k
                        sumD(j) = sum(D(label==j,j));
                    <span class="keyword">end</span>
                    bestsumD = sumD;
                    bestD = D;
                <span class="keyword">end</span>
            <span class="keyword">else</span>
                <span class="keyword">if</span> any(label ~= last)
                    W=full(X*center');
                <span class="keyword">end</span>
                D = 1-W;
                <span class="keyword">for</span> j = 1:k
                    sumD(j) = sum(D(label==j,j));
                <span class="keyword">end</span>
                <span class="keyword">if</span> sum(sumD) &lt; sum(bestsumD)
                    bestlabel = label;
                    bestcenter = center;
                    bestsumD = sumD;
                    bestD = D;
                <span class="keyword">end</span>
            <span class="keyword">end</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>

label = bestlabel;
center = bestcenter;
<span class="keyword">if</span> reps&gt;1
    sumD = bestsumD;
    D = bestD;
<span class="keyword">elseif</span> nargout &gt; 3
    <span class="keyword">switch</span> distance
        <span class="keyword">case</span> <span class="string">'sqeuclidean'</span>
            <span class="keyword">if</span> it&gt;=maxit
                aa = full(sum(X.*X,2));
                bb = full(sum(center.*center,2));
                ab = full(X*center');
                D = bsxfun(@plus,aa,bb') - 2*ab;
                D(D&lt;0) = 0;
            <span class="keyword">else</span>
                aa = full(sum(X.*X,2));
                D = aa(:,ones(1,k)) + D;
                D(D&lt;0) = 0;
            <span class="keyword">end</span>
            D = sqrt(D);
        <span class="keyword">case</span> <span class="string">'cosine'</span>
            <span class="keyword">if</span> it&gt;=maxit
                W=full(X*center');
            <span class="keyword">end</span>
            D = 1-W;
    <span class="keyword">end</span>
    <span class="keyword">for</span> j = 1:k
        sumD(j) = sum(D(label==j,j));
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><pre class="codeoutput error">Error using litekmeans (line 98)
At least two input arguments required.
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2015b</a><br></p></div><!--
##### SOURCE BEGIN #####
function [label, center, bCon, sumD, D] = litekmeans(X, k, varargin)
%LITEKMEANS K-means clustering, accelerated by matlab matrix operations.
%
%   label = LITEKMEANS(X, K) partitions the points in the N-by-P data matrix
%   X into K clusters.  This partition minimizes the sum, over all
%   clusters, of the within-cluster sums of point-to-cluster-centroid
%   distances.  Rows of X correspond to points, columns correspond to
%   variables.  KMEANS returns an N-by-1 vector label containing the
%   cluster indices of each point.
%
%   [label, center] = LITEKMEANS(X, K) returns the K cluster centroid
%   locations in the K-by-P matrix center.
%
%   [label, center, bCon] = LITEKMEANS(X, K) returns the bool value bCon to
%   indicate whether the iteration is converged.  
%
%   [label, center, bCon, SUMD] = LITEKMEANS(X, K) returns the
%   within-cluster sums of point-to-centroid distances in the 1-by-K vector
%   sumD.    
%
%   [label, center, bCon, SUMD, D] = LITEKMEANS(X, K) returns
%   distances from each point to every centroid in the N-by-K matrix D. 
%
%   [ ... ] = LITEKMEANS(..., 'PARAM1',val1, 'PARAM2',val2, ...) specifies
%   optional parameter name/value pairs to control the iterative algorithm
%   used by KMEANS.  Parameters are:
%
%   'Distance' - Distance measure, in P-dimensional space, that KMEANS
%      should minimize with respect to.  Choices are:
%            {'sqEuclidean'} - Squared Euclidean distance (the default)
%             'cosine'       - One minus the cosine of the included angle
%                              between points (treated as vectors). Each
%                              row of X SHOULD be normalized to unit. If
%                              the intial center matrix is provided, it
%                              SHOULD also be normalized.
%
%   'Start' - Method used to choose initial cluster centroid positions,
%      sometimes known as "seeds".  Choices are:
%         {'sample'}  - Select K observations from X at random (the default)
%          'cluster' - Perform preliminary clustering phase on random 10%
%                      subsample of X.  This preliminary phase is itself
%                      initialized using 'sample'. An additional parameter
%                      clusterMaxIter can be used to control the maximum
%                      number of iterations in each preliminary clustering
%                      problem.
%           matrix   - A K-by-P matrix of starting locations; or a K-by-1
%                      indicate vector indicating which K points in X
%                      should be used as the initial center.  In this case,
%                      you can pass in [] for K, and KMEANS infers K from
%                      the first dimension of the matrix.
%
%   'MaxIter'    - Maximum number of iterations allowed.  Default is 100.
%
%   'Replicates' - Number of times to repeat the clustering, each with a
%                  new set of initial centroids. Default is 1. If the
%                  initial centroids are provided, the replicate will be
%                  automatically set to be 1.
%
% 'clusterMaxIter' - Only useful when 'Start' is 'cluster'. Maximum number
%                    of iterations of the preliminary clustering phase.
%                    Default is 10.  
%
%
%    Examples:
%
%       fea = rand(500,10);
%       [label, center] = litekmeans(fea, 5, 'MaxIter', 50);
%
%       fea = rand(500,10);
%       [label, center] = litekmeans(fea, 5, 'MaxIter', 50, 'Replicates', 10);
%
%       fea = rand(500,10);
%       [label, center, bCon, sumD, D] = litekmeans(fea, 5, 'MaxIter', 50);
%       TSD = sum(sumD);
%
%       fea = rand(500,10);
%       initcenter = rand(5,10);
%       [label, center] = litekmeans(fea, 5, 'MaxIter', 50, 'Start', initcenter);
%
%       fea = rand(500,10);
%       idx=randperm(500);
%       [label, center] = litekmeans(fea, 5, 'MaxIter', 50, 'Start', idx(1:5));
%
%
%   See also KMEANS
%
%    [Cite] Deng Cai, "Litekmeans: the fastest matlab implementation of
%           kmeans," Available at:
%           http://www.zjucadcg.cn/dengcai/Data/Clustering.html, 2011. 
%
%   version 2.0 REPLACE_WITH_DASH_DASHDecember/2011
%   version 1.0 REPLACE_WITH_DASH_DASHNovember/2011
%
%   Written by Deng Cai (dengcai AT gmail.com)


if nargin < 2
    error('litekmeans:TooFewInputs','At least two input arguments required.');
end

[n, p] = size(X);


pnames = {   'distance' 'start'   'maxiter'  'replicates' 'onlinephase' 'clustermaxiter'};
dflts =  {'sqeuclidean' 'sample'       []        []        'off'              []        };
[eid,errmsg,distance,start,maxit,reps,online,clustermaxit] = getargs(pnames, dflts, varargin{:});
if ~isempty(eid)
    error(sprintf('litekmeans:%s',eid),errmsg);
end

if ischar(distance)
    distNames = {'sqeuclidean','cosine'};
    j = strcmpi(distance, distNames);
    j = find(j);
    if length(j) > 1
        error('litekmeans:AmbiguousDistance', ...
            'Ambiguous ''Distance'' parameter value:  %s.', distance);
    elseif isempty(j)
        error('litekmeans:UnknownDistance', ...
            'Unknown ''Distance'' parameter value:  %s.', distance);
    end
    distance = distNames{j};
else
    error('litekmeans:InvalidDistance', ...
        'The ''Distance'' parameter value must be a string.');
end


center = [];
if ischar(start)
    startNames = {'sample','cluster'};
    j = find(strncmpi(start,startNames,length(start)));
    if length(j) > 1
        error(message('litekmeans:AmbiguousStart', start));
    elseif isempty(j)
        error(message('litekmeans:UnknownStart', start));
    elseif isempty(k)
        error('litekmeans:MissingK', ...
            'You must specify the number of clusters, K.');
    end
    if j == 2
        if floor(.1*n) < 5*k
            j = 1;
        end
    end
    start = startNames{j};
elseif isnumeric(start)
    if size(start,2) == p
        center = start;
    elseif (size(start,2) == 1 || size(start,1) == 1)
        center = X(start,:);
    else
        error('litekmeans:MisshapedStart', ...
            'The ''Start'' matrix must have the same number of columns as X.');
    end
    if isempty(k)
        k = size(center,1);
    elseif (k ~= size(center,1))
        error('litekmeans:MisshapedStart', ...
            'The ''Start'' matrix must have K rows.');
    end
    start = 'numeric';
else
    error('litekmeans:InvalidStart', ...
        'The ''Start'' parameter value must be a string or a numeric matrix or array.');
end

% The maximum iteration number is default 100
if isempty(maxit)
    maxit = 100;
end

% The maximum iteration number for preliminary clustering phase on random
% 10% subsamples is default 10 
if isempty(clustermaxit)
    clustermaxit = 10;
end


% Assume one replicate
if isempty(reps) || ~isempty(center)
    reps = 1;
end

if ~(isscalar(k) && isnumeric(k) && isreal(k) && k > 0 && (round(k)==k))
    error('litekmeans:InvalidK', ...
        'X must be a positive integer value.');
elseif n < k
    error('litekmeans:TooManyClusters', ...
        'X must have more rows than the number of clusters.');
end


bestlabel = [];
sumD = zeros(1,k);
bCon = false;

for t=1:reps
    switch start
        case 'sample'
            center = X(randsample(n,k),:);
        case 'cluster'
            Xsubset = X(randsample(n,floor(.1*n)),:);
            [dump, center] = litekmeans(Xsubset, k, varargin{:}, 'start','sample', 'replicates',1 ,'MaxIter',clustermaxit);
        case 'numeric'
    end
    
    last = 0;label=1;
    it=0;
    
    switch distance
        case 'sqeuclidean'
            while any(label ~= last) && it<maxit
                last = label;
                
                bb = full(sum(center.*center,2)');
                ab = full(X*center');
                D = bb(ones(1,n),:) - 2*ab;
                
                [val,label] = min(D,[],2); % assign samples to the nearest centers
                ll = unique(label);
                if length(ll) < k
                    %disp([num2str(k-length(ll)),' clusters dropped at iter ',num2str(it)]);
                    missCluster = 1:k;
                    missCluster(ll) = [];
                    missNum = length(missCluster);
                    
                    aa = sum(X.*X,2);
                    val = aa + val;
                    [dump,idx] = sort(val,1,'descend');
                    label(idx(1:missNum)) = missCluster;
                end
                E = sparse(1:n,label,1,n,k,n);  % transform label into indicator matrix
                center = full((E*spdiags(1./sum(E,1)',0,k,k))'*X);    % compute center of each cluster
                it=it+1;
            end
            if it<maxit
                bCon = true;
            end
            if isempty(bestlabel)
                bestlabel = label;
                bestcenter = center;
                if reps>1
                    if it>=maxit
                        aa = full(sum(X.*X,2));
                        bb = full(sum(center.*center,2));
                        ab = full(X*center');
                        D = bsxfun(@plus,aa,bb') - 2*ab;
                        D(D<0) = 0;
                    else
                        aa = full(sum(X.*X,2));
                        D = aa(:,ones(1,k)) + D;
                        D(D<0) = 0;
                    end
                    D = sqrt(D);
                    for j = 1:k
                        sumD(j) = sum(D(label==j,j));
                    end
                    bestsumD = sumD;
                    bestD = D;
                end
            else
                if it>=maxit
                    aa = full(sum(X.*X,2));
                    bb = full(sum(center.*center,2));
                    ab = full(X*center');
                    D = bsxfun(@plus,aa,bb') - 2*ab;
                    D(D<0) = 0;
                else
                    aa = full(sum(X.*X,2));
                    D = aa(:,ones(1,k)) + D;
                    D(D<0) = 0;
                end
                D = sqrt(D);
                for j = 1:k
                    sumD(j) = sum(D(label==j,j));
                end
                if sum(sumD) < sum(bestsumD)
                    bestlabel = label;
                    bestcenter = center;
                    bestsumD = sumD;
                    bestD = D;
                end
            end
        case 'cosine'
            while any(label ~= last) && it<maxit
                last = label;
                W=full(X*center');
                [val,label] = max(W,[],2); % assign samples to the nearest centers
                ll = unique(label);
                if length(ll) < k
                    missCluster = 1:k;
                    missCluster(ll) = [];
                    missNum = length(missCluster);
                    [dump,idx] = sort(val);
                    label(idx(1:missNum)) = missCluster;
                end
                E = sparse(1:n,label,1,n,k,n);  % transform label into indicator matrix
                center = full((E*spdiags(1./sum(E,1)',0,k,k))'*X);    % compute center of each cluster
                centernorm = sqrt(sum(center.^2, 2));
                center = center ./ centernorm(:,ones(1,p));
                it=it+1;
            end
            if it<maxit
                bCon = true;
            end
            if isempty(bestlabel)
                bestlabel = label;
                bestcenter = center;
                if reps>1
                    if any(label ~= last)
                        W=full(X*center');
                    end
                    D = 1-W;
                    for j = 1:k
                        sumD(j) = sum(D(label==j,j));
                    end
                    bestsumD = sumD;
                    bestD = D;
                end
            else
                if any(label ~= last)
                    W=full(X*center');
                end
                D = 1-W;
                for j = 1:k
                    sumD(j) = sum(D(label==j,j));
                end
                if sum(sumD) < sum(bestsumD)
                    bestlabel = label;
                    bestcenter = center;
                    bestsumD = sumD;
                    bestD = D;
                end
            end
    end
end

label = bestlabel;
center = bestcenter;
if reps>1
    sumD = bestsumD;
    D = bestD;
elseif nargout > 3
    switch distance
        case 'sqeuclidean'
            if it>=maxit
                aa = full(sum(X.*X,2));
                bb = full(sum(center.*center,2));
                ab = full(X*center');
                D = bsxfun(@plus,aa,bb') - 2*ab;
                D(D<0) = 0;
            else
                aa = full(sum(X.*X,2));
                D = aa(:,ones(1,k)) + D;
                D(D<0) = 0;
            end
            D = sqrt(D);
        case 'cosine'
            if it>=maxit
                W=full(X*center');
            end
            D = 1-W;
    end
    for j = 1:k
        sumD(j) = sum(D(label==j,j));
    end
end






##### SOURCE END #####
--></body></html>