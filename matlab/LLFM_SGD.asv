% load training data
% train_X, train_Y
load('training_data');
[num_sample, p] = size(train_X);
y_max = max(train_Y);
y_min = min(train_Y);

% parameters
iter_num = 1;
learning_rate = 0.01;
factors_num = 10;
reg_w = 0.1;
reg_v = 0.01;

% locally linear
% anchor points
anchors_num = 100;

% knn
nearest_neighbor = 10;

w0 = rand(anchors_num,1);
W = rand(anchors_num,p);
V = rand(p,factors_num,anchors_num);

mse = zeros(1,iter_num*num_sample);
loss = zeros(1,iter_num*num_sample);

% get anchor points
fprintf('Start K-means...\n');
[~, anchors, ~, ~, ~] = litekmeans(train_X, anchors_num);
fprintf('K-means done..\n');

for i=1:iter_num
    % do shuffle
    re_idx = randperm(num_sample);
    X_train = train_X(re_idx,:);
    Y_train = train_Y(re_idx);
    
    % SGD
    tic;
    for j=1:num_sample
        if mod(j,1000)==0
            toc;
            tic;
            fprintf('processing %dth sample\n', j);
        end
        
        X = X_train(j,:);
        y = Y_train(j,:);
        
        % pick anchor points
        [anchor_idx, gamma] = knn(anchors, X, nearest_neighbor);
        
%         factor_part = 0.0;
%         for k=1:nearest_neighbor
%             temp_V = squeeze(V(anchor_idx(k),:,:));
%             tmp = sum(repmat(X',1,factors_num).*temp_V);
%             factor_part = factor_part + gamma(k)*(sum(tmp.^2) - sum(sum(repmat((X').^2,1,factors_num).*(temp_V.^2))))/2;
%         end

        temp_V = V(:,:,anchor_idx);
        X_ = repmat(X', [1, factors_num, nearest_neighbor]);
        tmp = X_.*temp_V;
        factor_part = gamma * (squeeze(sum(sum(tmp.^2,1),2)) - squeeze(sum(sum((X_.^2).*(temp_V.*2),1),2)));
        
        
        
        y_predict = sum(w0(anchor_idx)) + sum(W(anchor_idx,:)*X') + factor_part;
        
%         fprintf('%f\n', y_predict);
        
        % prune
        if y_predict < y_min
            y_predict = y_min;
        end
        
        if y_predict > y_max
            y_predict = y_max;
        end
        
        err = y_predict - y;
        
        idx = (i-1)*num_sample + j;
        loss(idx) = err^2;
        mse(idx) = sum(loss)/idx;
        
        % update parameters
        w0(anchor_idx) = w0(anchor_idx) - learning_rate * gamma' .* (2 * err + 2*reg_w*w0(anchor_idx));
        W(anchor_idx,:) = W(anchor_idx,:) - learning_rate * repmat(gamma',1,p) .* (2*err*repmat(X,[nearest_neighbor, 1]) + 2*reg_w*W(anchor_idx,:));
        
%         for k=1:nearest_neighbor
%             temp_V = squeeze(V(:,:,anchor_idx(k)));
%             V(:,:,anchor_idx(k)) = temp_V - learning_rate * gamma(k) * (2*err*(repmat(X',1,factors_num).*(repmat(X*temp_V,p,1)-repmat(X',1,factors_num).*temp_V)) + 2*reg_v*squeeze(temp_V));
%         end
        
        t
        V(:,:,anchor_idx) = V(:,:,anchor_idx) - learning_rate * repmat(gamma,p,1,nearest_neighbor)...
            *(2 * err * X_ .*()  + 2*reg_w*W(anchor_idx,:));
        
%         V = V - learning_rate * (2*err*(repmat(X',1,factors_num).*(repmat(X*temp_V,p,1)-repmat(X',[nearest_neighbor, 1,factors_num]).*V)) + 2*reg_v*V);
    end
end

%%
% plot
plot(mse);
xlabel('Number of samples seen');
ylabel('MSE');
grid on;