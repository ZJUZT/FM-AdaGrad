{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评分矩阵构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集：<http://www.grouplens.org/system/files/ml-100k.zip>，（u_id, movie_id, rating, timestamp）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从文件中读取评分记录，生成评分矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Read in data\n",
    "def loadData(filename,path=\"ml-100k/\"):\n",
    "    data = []\n",
    "    y = []\n",
    "    users=set()\n",
    "    items=set()\n",
    "    with open(path+filename) as f:\n",
    "        for line in f:\n",
    "            (user,movieid,rating,ts)=line.split('\\t')\n",
    "#             data.append({ \"user_id\": str(user), \"movie_id\": str(movieid)})\n",
    "            data.append([int(user),int(movieid)])\n",
    "            y.append(float(rating))\n",
    "            users.add(user)\n",
    "            items.add(movieid)\n",
    "\n",
    "    return (np.array(data), np.array(y), users, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到训练集以及测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_data, y_train, train_users, train_items) = loadData(\"ua.base\")\n",
    "(test_data, y_test, test_users, test_items) = loadData(\"ua.test\")\n",
    "# train_data[:,1]\n",
    "(num_user,num_mv) = np.amax(train_data, axis=0)\n",
    "N = len(train_data)\n",
    "# num_user, num_mv\n",
    "\n",
    "aa_p   = train_data[:,0]-1;\n",
    "aa_m   = train_data[:,1]-1;\n",
    "rating = y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "PMF（概率矩阵分解）\n",
    "U - 用户隐式矩阵；V - 物品隐式矩阵\n",
    "<br>\n",
    "∆xt = -ηgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到损失函数\n",
    "![](img/2.png)\n",
    "对U、V求偏导，更新U、V\n",
    "![](img/3.png)\n",
    "![](img/4.png)\n",
    "![](img/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据求偏导结果更新用户和物品的隐式特征矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0 \tloss:  1.69757734454\n",
      "Iter  1 \tloss:  1.69112190714\n",
      "Iter  2 \tloss:  1.68471980167\n",
      "Iter  3 \tloss:  1.67837103424\n",
      "Iter  4 \tloss:  1.67207561646\n",
      "Iter  5 \tloss:  1.66583356363\n",
      "Iter  6 \tloss:  1.65964489311\n",
      "Iter  7 \tloss:  1.65350962276\n",
      "Iter  8 \tloss:  1.64742776964\n",
      "Iter  9 \tloss:  1.64139934873\n",
      "Iter  10 \tloss:  1.63542437183\n",
      "Iter  11 \tloss:  1.62950284651\n",
      "Iter  12 \tloss:  1.62363477524\n",
      "Iter  13 \tloss:  1.61782015454\n",
      "Iter  14 \tloss:  1.61205897426\n",
      "Iter  15 \tloss:  1.6063512169\n",
      "Iter  16 \tloss:  1.60069685702\n",
      "Iter  17 \tloss:  1.59509586076\n",
      "Iter  18 \tloss:  1.58954818535\n",
      "Iter  19 \tloss:  1.58405377874\n",
      "Iter  20 \tloss:  1.57861257923\n",
      "Iter  21 \tloss:  1.57322451522\n",
      "Iter  22 \tloss:  1.56788950496\n",
      "Iter  23 \tloss:  1.56260745632\n",
      "Iter  24 \tloss:  1.55737826668\n",
      "Iter  25 \tloss:  1.55220182282\n",
      "Iter  26 \tloss:  1.54707800079\n",
      "Iter  27 \tloss:  1.54200666592\n",
      "Iter  28 \tloss:  1.53698767278\n",
      "Iter  29 \tloss:  1.53202086521\n",
      "Iter  30 \tloss:  1.52710607635\n",
      "Iter  31 \tloss:  1.52224312872\n",
      "Iter  32 \tloss:  1.51743183433\n",
      "Iter  33 \tloss:  1.51267199475\n",
      "Iter  34 \tloss:  1.50796340128\n",
      "Iter  35 \tloss:  1.5033058351\n",
      "Iter  36 \tloss:  1.49869906743\n",
      "Iter  37 \tloss:  1.49414285973\n",
      "Iter  38 \tloss:  1.48963696387\n",
      "Iter  39 \tloss:  1.4851811224\n",
      "Iter  40 \tloss:  1.48077506871\n",
      "Iter  41 \tloss:  1.47641852731\n",
      "Iter  42 \tloss:  1.47211121405\n",
      "Iter  43 \tloss:  1.46785283641\n",
      "Iter  44 \tloss:  1.46364309371\n",
      "Iter  45 \tloss:  1.45948167741\n",
      "Iter  46 \tloss:  1.45536827138\n",
      "Iter  47 \tloss:  1.45130255218\n",
      "Iter  48 \tloss:  1.44728418932\n",
      "Iter  49 \tloss:  1.44331284557\n",
      "Iter  50 \tloss:  1.43938817724\n",
      "Iter  51 \tloss:  1.43550983447\n",
      "Iter  52 \tloss:  1.43167746151\n",
      "Iter  53 \tloss:  1.42789069702\n",
      "Iter  54 \tloss:  1.42414917434\n",
      "Iter  55 \tloss:  1.42045252183\n",
      "Iter  56 \tloss:  1.41680036311\n",
      "Iter  57 \tloss:  1.41319231734\n",
      "Iter  58 \tloss:  1.40962799956\n",
      "Iter  59 \tloss:  1.40610702091\n",
      "Iter  60 \tloss:  1.40262898897\n",
      "Iter  61 \tloss:  1.39919350796\n",
      "Iter  62 \tloss:  1.39580017908\n",
      "Iter  63 \tloss:  1.39244860075\n",
      "Iter  64 \tloss:  1.38913836887\n",
      "Iter  65 \tloss:  1.38586907709\n",
      "Iter  66 \tloss:  1.38264031704\n",
      "Iter  67 \tloss:  1.37945167863\n",
      "Iter  68 \tloss:  1.37630275022\n",
      "Iter  69 \tloss:  1.37319311894\n",
      "Iter  70 \tloss:  1.37012237086\n",
      "Iter  71 \tloss:  1.36709009125\n",
      "Iter  72 \tloss:  1.36409586478\n",
      "Iter  73 \tloss:  1.36113927576\n",
      "Iter  74 \tloss:  1.35821990833\n",
      "Iter  75 \tloss:  1.3553373467\n",
      "Iter  76 \tloss:  1.35249117527\n",
      "Iter  77 \tloss:  1.34968097891\n",
      "Iter  78 \tloss:  1.3469063431\n",
      "Iter  79 \tloss:  1.34416685411\n",
      "Iter  80 \tloss:  1.34146209918\n",
      "Iter  81 \tloss:  1.33879166669\n",
      "Iter  82 \tloss:  1.33615514631\n",
      "Iter  83 \tloss:  1.33355212919\n",
      "Iter  84 \tloss:  1.33098220804\n",
      "Iter  85 \tloss:  1.32844497735\n",
      "Iter  86 \tloss:  1.32594003347\n",
      "Iter  87 \tloss:  1.32346697479\n",
      "Iter  88 \tloss:  1.3210254018\n",
      "Iter  89 \tloss:  1.31861491727\n",
      "Iter  90 \tloss:  1.31623512635\n",
      "Iter  91 \tloss:  1.31388563666\n",
      "Iter  92 \tloss:  1.31156605839\n",
      "Iter  93 \tloss:  1.30927600444\n",
      "Iter  94 \tloss:  1.30701509046\n",
      "Iter  95 \tloss:  1.30478293497\n",
      "Iter  96 \tloss:  1.30257915943\n",
      "Iter  97 \tloss:  1.30040338833\n",
      "Iter  98 \tloss:  1.29825524924\n",
      "Iter  99 \tloss:  1.29613437289\n",
      "Iter  100 \tloss:  1.29404039325\n",
      "Iter  101 \tloss:  1.29197294755\n",
      "Iter  102 \tloss:  1.28993167639\n",
      "Iter  103 \tloss:  1.28791622371\n",
      "Iter  104 \tloss:  1.28592623694\n",
      "Iter  105 \tloss:  1.28396136694\n",
      "Iter  106 \tloss:  1.2820212681\n",
      "Iter  107 \tloss:  1.28010559836\n",
      "Iter  108 \tloss:  1.27821401926\n",
      "Iter  109 \tloss:  1.2763461959\n",
      "Iter  110 \tloss:  1.27450179706\n",
      "Iter  111 \tloss:  1.27268049515\n",
      "Iter  112 \tloss:  1.27088196625\n",
      "Iter  113 \tloss:  1.26910589012\n",
      "Iter  114 \tloss:  1.26735195024\n",
      "Iter  115 \tloss:  1.26561983377\n",
      "Iter  116 \tloss:  1.26390923161\n",
      "Iter  117 \tloss:  1.26221983834\n",
      "Iter  118 \tloss:  1.26055135229\n",
      "Iter  119 \tloss:  1.2589034755\n",
      "Iter  120 \tloss:  1.2572759137\n",
      "Iter  121 \tloss:  1.25566837637\n",
      "Iter  122 \tloss:  1.25408057665\n",
      "Iter  123 \tloss:  1.25251223139\n",
      "Iter  124 \tloss:  1.25096306111\n",
      "Iter  125 \tloss:  1.24943279002\n",
      "Iter  126 \tloss:  1.24792114595\n",
      "Iter  127 \tloss:  1.24642786039\n",
      "Iter  128 \tloss:  1.24495266842\n",
      "Iter  129 \tloss:  1.24349530874\n",
      "Iter  130 \tloss:  1.24205552361\n",
      "Iter  131 \tloss:  1.24063305887\n",
      "Iter  132 \tloss:  1.23922766386\n",
      "Iter  133 \tloss:  1.23783909144\n",
      "Iter  134 \tloss:  1.23646709795\n",
      "Iter  135 \tloss:  1.23511144319\n",
      "Iter  136 \tloss:  1.23377189037\n",
      "Iter  137 \tloss:  1.23244820612\n",
      "Iter  138 \tloss:  1.23114016042\n",
      "Iter  139 \tloss:  1.2298475266\n",
      "Iter  140 \tloss:  1.22857008128\n",
      "Iter  141 \tloss:  1.22730760439\n",
      "Iter  142 \tloss:  1.22605987908\n",
      "Iter  143 \tloss:  1.2248266917\n",
      "Iter  144 \tloss:  1.22360783182\n",
      "Iter  145 \tloss:  1.22240309212\n",
      "Iter  146 \tloss:  1.22121226842\n",
      "Iter  147 \tloss:  1.22003515958\n",
      "Iter  148 \tloss:  1.21887156754\n",
      "Iter  149 \tloss:  1.21772129723\n",
      "Iter  150 \tloss:  1.21658415657\n",
      "Iter  151 \tloss:  1.21545995639\n",
      "Iter  152 \tloss:  1.21434851046\n",
      "Iter  153 \tloss:  1.21324963539\n",
      "Iter  154 \tloss:  1.21216315062\n",
      "Iter  155 \tloss:  1.21108887842\n",
      "Iter  156 \tloss:  1.21002664377\n",
      "Iter  157 \tloss:  1.20897627443\n",
      "Iter  158 \tloss:  1.20793760081\n",
      "Iter  159 \tloss:  1.206910456\n",
      "Iter  160 \tloss:  1.20589467567\n",
      "Iter  161 \tloss:  1.20489009812\n",
      "Iter  162 \tloss:  1.20389656417\n",
      "Iter  163 \tloss:  1.20291391716\n",
      "Iter  164 \tloss:  1.2019420029\n",
      "Iter  165 \tloss:  1.20098066965\n",
      "Iter  166 \tloss:  1.20002976808\n",
      "Iter  167 \tloss:  1.19908915122\n",
      "Iter  168 \tloss:  1.19815867445\n",
      "Iter  169 \tloss:  1.19723819545\n",
      "Iter  170 \tloss:  1.19632757417\n",
      "Iter  171 \tloss:  1.19542667281\n",
      "Iter  172 \tloss:  1.19453535574\n",
      "Iter  173 \tloss:  1.19365348955\n",
      "Iter  174 \tloss:  1.19278094291\n",
      "Iter  175 \tloss:  1.19191758665\n",
      "Iter  176 \tloss:  1.19106329363\n",
      "Iter  177 \tloss:  1.19021793879\n",
      "Iter  178 \tloss:  1.18938139903\n",
      "Iter  179 \tloss:  1.18855355328\n",
      "Iter  180 \tloss:  1.18773428238\n",
      "Iter  181 \tloss:  1.18692346911\n",
      "Iter  182 \tloss:  1.18612099811\n",
      "Iter  183 \tloss:  1.18532675591\n",
      "Iter  184 \tloss:  1.18454063084\n",
      "Iter  185 \tloss:  1.18376251303\n",
      "Iter  186 \tloss:  1.18299229439\n",
      "Iter  187 \tloss:  1.18222986856\n",
      "Iter  188 \tloss:  1.1814751309\n",
      "Iter  189 \tloss:  1.18072797845\n",
      "Iter  190 \tloss:  1.17998830989\n",
      "Iter  191 \tloss:  1.17925602557\n",
      "Iter  192 \tloss:  1.17853102739\n",
      "Iter  193 \tloss:  1.17781321887\n",
      "Iter  194 \tloss:  1.17710250505\n",
      "Iter  195 \tloss:  1.17639879252\n",
      "Iter  196 \tloss:  1.17570198933\n",
      "Iter  197 \tloss:  1.17501200505\n",
      "Iter  198 \tloss:  1.17432875068\n",
      "Iter  199 \tloss:  1.17365213862\n"
     ]
    }
   ],
   "source": [
    "num_features = 10\n",
    "lamda_U = 0.1\n",
    "lamda_V = 0.1\n",
    "learning_rate = 0.00001\n",
    "\n",
    "U = np.random.rand(num_user, num_features)\n",
    "V = np.random.rand(num_mv, num_features)\n",
    "\n",
    "iter_num = 200\n",
    "loss_gd = []\n",
    "\n",
    "for k in range(iter_num):\n",
    "    predict_matrix = np.sum(U[aa_p,:]*V[aa_m,:], axis=1)\n",
    "    IO = np.array([predict_matrix-rating]).T\n",
    "\n",
    "    Ix_U = IO * V[aa_m,:] + lamda_U * U[aa_p,:]\n",
    "    Ix_V = IO * U[aa_p,:] + lamda_V * V[aa_m,:]\n",
    "    l = np.sum(np.square(IO)) + 1/2.0*lamda_U*np.sum(np.square(U)) + 1/2.0*lamda_V*np.sum(np.square(V))\n",
    "\n",
    "    l = math.sqrt(l/N)\n",
    "    \n",
    "    loss_gd.append(l)\n",
    "    \n",
    "    print \"Iter \" , k  , \"\\t\" + \"loss: \" , l\n",
    "    du = np.zeros((num_user, num_features))\n",
    "    dv = np.zeros((num_mv, num_features))\n",
    "    for i in range(N):\n",
    "        du[aa_p[i],:] = du[aa_p[i],:] + Ix_V[i,:]\n",
    "        dv[aa_m[i],:] = dv[aa_m[i],:] + Ix_U[i,:]\n",
    "    V = V - learning_rate*dv\n",
    "    U = U - learning_rate*du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x156cdcd0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBLu/wEIC7XSAaNfywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d75290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(loss_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Per Dimensional Solution\n",
    "对于PMF而言，用户的隐式特征矩阵是一个多维矩阵，即拥有多个feature，每一个维度的下降速率不同，我们可以通过为每一维维护learning rate，达到优化Gradient Decent的目的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "∆xt = ρ∆xt−1 − ηgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0 \tloss:  1.64682621991\n",
      "Iter  1 \tloss:  1.64114148687\n",
      "Iter  2 \tloss:  1.63042218514\n",
      "Iter  3 \tloss:  1.61532514402\n",
      "Iter  4 \tloss:  1.59650644514\n",
      "Iter  5 \tloss:  1.5746167853\n",
      "Iter  6 \tloss:  1.55029768297\n",
      "Iter  7 \tloss:  1.5241772301\n",
      "Iter  8 \tloss:  1.49686455905\n",
      "Iter  9 \tloss:  1.46894258594\n",
      "Iter  10 \tloss:  1.44095896249\n",
      "Iter  11 \tloss:  1.41341554303\n",
      "Iter  12 \tloss:  1.38675704803\n",
      "Iter  13 \tloss:  1.36135994294\n",
      "Iter  14 \tloss:  1.33752279394\n",
      "Iter  15 \tloss:  1.31545943786\n",
      "Iter  16 \tloss:  1.29529615686\n",
      "Iter  17 \tloss:  1.27707366233\n",
      "Iter  18 \tloss:  1.26075411117\n",
      "Iter  19 \tloss:  1.24623270588\n",
      "Iter  20 \tloss:  1.23335280535\n",
      "Iter  21 \tloss:  1.22192303059\n",
      "Iter  22 \tloss:  1.21173467121\n",
      "Iter  23 \tloss:  1.20257779975\n",
      "Iter  24 \tloss:  1.19425482842\n",
      "Iter  25 \tloss:  1.18659070279\n",
      "Iter  26 \tloss:  1.17943941656\n",
      "Iter  27 \tloss:  1.17268696791\n",
      "Iter  28 \tloss:  1.16625120775\n",
      "Iter  29 \tloss:  1.16007923565\n",
      "Iter  30 \tloss:  1.1541430861\n",
      "Iter  31 \tloss:  1.14843443773\n",
      "Iter  32 \tloss:  1.14295899869\n",
      "Iter  33 \tloss:  1.13773110022\n",
      "Iter  34 \tloss:  1.13276889018\n",
      "Iter  35 \tloss:  1.1280903776\n",
      "Iter  36 \tloss:  1.12371045088\n",
      "Iter  37 \tloss:  1.11963888417\n",
      "Iter  38 \tloss:  1.1158792626\n",
      "Iter  39 \tloss:  1.11242869946\n",
      "Iter  40 \tloss:  1.10927818449\n",
      "Iter  41 \tloss:  1.10641339041\n",
      "Iter  42 \tloss:  1.10381576929\n",
      "Iter  43 \tloss:  1.10146378787\n",
      "Iter  44 \tloss:  1.09933417587\n",
      "Iter  45 \tloss:  1.0974030903\n",
      "Iter  46 \tloss:  1.09564712813\n",
      "Iter  47 \tloss:  1.09404414674\n",
      "Iter  48 \tloss:  1.09257387509\n",
      "Iter  49 \tloss:  1.09121831751\n",
      "Iter  50 \tloss:  1.08996196594\n",
      "Iter  51 \tloss:  1.08879184617\n",
      "Iter  52 \tloss:  1.08769742875\n",
      "Iter  53 \tloss:  1.0866704378\n",
      "Iter  54 \tloss:  1.08570458967\n",
      "Iter  55 \tloss:  1.08479529151\n",
      "Iter  56 \tloss:  1.08393932518\n",
      "Iter  57 \tloss:  1.08313453775\n",
      "Iter  58 \tloss:  1.0823795546\n",
      "Iter  59 \tloss:  1.08167352618\n",
      "Iter  60 \tloss:  1.08101591507\n",
      "Iter  61 \tloss:  1.0804063259\n",
      "Iter  62 \tloss:  1.07984437756\n",
      "Iter  63 \tloss:  1.07932961455\n",
      "Iter  64 \tloss:  1.07886145262\n",
      "Iter  65 \tloss:  1.07843915297\n",
      "Iter  66 \tloss:  1.07806181874\n",
      "Iter  67 \tloss:  1.07772840771\n",
      "Iter  68 \tloss:  1.07743775571\n",
      "Iter  69 \tloss:  1.07718860593\n",
      "Iter  70 \tloss:  1.07697964012\n",
      "Iter  71 \tloss:  1.07680950894\n",
      "Iter  72 \tloss:  1.07667685913\n",
      "Iter  73 \tloss:  1.07658035654\n",
      "Iter  74 \tloss:  1.07651870416\n",
      "Iter  75 \tloss:  1.07649065537\n",
      "Iter  76 \tloss:  1.07649502258\n",
      "Iter  77 \tloss:  1.07653068198\n",
      "Iter  78 \tloss:  1.07659657506\n",
      "Iter  79 \tloss:  1.07669170765\n",
      "Iter  80 \tloss:  1.07681514742\n",
      "Iter  81 \tloss:  1.07696602018\n",
      "Iter  82 \tloss:  1.0771435058\n",
      "Iter  83 \tloss:  1.07734683407\n",
      "Iter  84 \tloss:  1.07757528068\n",
      "Iter  85 \tloss:  1.07782816378\n",
      "Iter  86 \tloss:  1.0781048409\n",
      "Iter  87 \tloss:  1.07840470644\n",
      "Iter  88 \tloss:  1.07872718964\n",
      "Iter  89 \tloss:  1.07907175294\n",
      "Iter  90 \tloss:  1.0794378906\n",
      "Iter  91 \tloss:  1.07982512756\n",
      "Iter  92 \tloss:  1.08023301841\n",
      "Iter  93 \tloss:  1.08066114638\n",
      "Iter  94 \tloss:  1.08110912228\n",
      "Iter  95 \tloss:  1.08157658347\n",
      "Iter  96 \tloss:  1.08206319267\n",
      "Iter  97 \tloss:  1.08256863671\n",
      "Iter  98 \tloss:  1.08309262521\n",
      "Iter  99 \tloss:  1.08363488928\n",
      "Iter  100 \tloss:  1.08419518007\n",
      "Iter  101 \tloss:  1.08477326744\n",
      "Iter  102 \tloss:  1.08536893862\n",
      "Iter  103 \tloss:  1.08598199692\n",
      "Iter  104 \tloss:  1.08661226053\n",
      "Iter  105 \tloss:  1.08725956144\n",
      "Iter  106 \tloss:  1.08792374445\n",
      "Iter  107 \tloss:  1.08860466628\n",
      "Iter  108 \tloss:  1.08930219483\n",
      "Iter  109 \tloss:  1.09001620854\n",
      "Iter  110 \tloss:  1.09074659584\n",
      "Iter  111 \tloss:  1.09149325478\n",
      "Iter  112 \tloss:  1.09225609261\n",
      "Iter  113 \tloss:  1.09303502563\n",
      "Iter  114 \tloss:  1.09382997894\n",
      "Iter  115 \tloss:  1.09464088632\n",
      "Iter  116 \tloss:  1.09546769019\n",
      "Iter  117 \tloss:  1.09631034155\n",
      "Iter  118 \tloss:  1.09716879993\n",
      "Iter  119 \tloss:  1.0980430334\n",
      "Iter  120 \tloss:  1.09893301857\n",
      "Iter  121 \tloss:  1.09983874054\n",
      "Iter  122 \tloss:  1.10076019288\n",
      "Iter  123 \tloss:  1.10169737758\n",
      "Iter  124 \tloss:  1.10265030493\n",
      "Iter  125 \tloss:  1.10361899343\n",
      "Iter  126 \tloss:  1.10460346967\n",
      "Iter  127 \tloss:  1.10560376809\n",
      "Iter  128 \tloss:  1.10661993082\n",
      "Iter  129 \tloss:  1.10765200742\n",
      "Iter  130 \tloss:  1.10870005463\n",
      "Iter  131 \tloss:  1.10976413608\n",
      "Iter  132 \tloss:  1.11084432202\n",
      "Iter  133 \tloss:  1.11194068898\n",
      "Iter  134 \tloss:  1.11305331948\n",
      "Iter  135 \tloss:  1.11418230174\n",
      "Iter  136 \tloss:  1.11532772937\n",
      "Iter  137 \tloss:  1.1164897011\n",
      "Iter  138 \tloss:  1.11766832051\n",
      "Iter  139 \tloss:  1.1188636958\n",
      "Iter  140 \tloss:  1.12007593958\n",
      "Iter  141 \tloss:  1.12130516867\n",
      "Iter  142 \tloss:  1.12255150401\n",
      "Iter  143 \tloss:  1.12381507048\n",
      "Iter  144 \tloss:  1.12509599683\n",
      "Iter  145 \tloss:  1.12639441566\n",
      "Iter  146 \tloss:  1.12771046337\n",
      "Iter  147 \tloss:  1.1290442802\n",
      "Iter  148 \tloss:  1.13039601023\n",
      "Iter  149 \tloss:  1.13176580146\n",
      "Iter  150 \tloss:  1.1331538059\n",
      "Iter  151 \tloss:  1.13456017968\n",
      "Iter  152 \tloss:  1.13598508314\n",
      "Iter  153 \tloss:  1.13742868098\n",
      "Iter  154 \tloss:  1.1388911424\n",
      "Iter  155 \tloss:  1.14037264124\n",
      "Iter  156 \tloss:  1.14187335615\n",
      "Iter  157 \tloss:  1.14339347072\n",
      "Iter  158 \tloss:  1.14493317365\n",
      "Iter  159 \tloss:  1.14649265887\n",
      "Iter  160 \tloss:  1.14807212574\n",
      "Iter  161 \tloss:  1.14967177913\n",
      "Iter  162 \tloss:  1.15129182957\n",
      "Iter  163 \tloss:  1.15293249342\n",
      "Iter  164 \tloss:  1.15459399289\n",
      "Iter  165 \tloss:  1.15627655626\n",
      "Iter  166 \tloss:  1.1579804179\n",
      "Iter  167 \tloss:  1.15970581838\n",
      "Iter  168 \tloss:  1.16145300457\n",
      "Iter  169 \tloss:  1.16322222972\n",
      "Iter  170 \tloss:  1.16501375352\n",
      "Iter  171 \tloss:  1.16682784215\n",
      "Iter  172 \tloss:  1.16866476839\n",
      "Iter  173 \tloss:  1.17052481165\n",
      "Iter  174 \tloss:  1.17240825802\n",
      "Iter  175 \tloss:  1.17431540037\n",
      "Iter  176 \tloss:  1.17624653838\n",
      "Iter  177 \tloss:  1.17820197861\n",
      "Iter  178 \tloss:  1.18018203458\n",
      "Iter  179 \tloss:  1.18218702683\n",
      "Iter  180 \tloss:  1.184217283\n",
      "Iter  181 \tloss:  1.18627313793\n",
      "Iter  182 \tloss:  1.18835493371\n",
      "Iter  183 \tloss:  1.19046301985\n",
      "Iter  184 \tloss:  1.19259775333\n",
      "Iter  185 \tloss:  1.19475949874\n",
      "Iter  186 \tloss:  1.19694862841\n",
      "Iter  187 \tloss:  1.19916552253\n",
      "Iter  188 \tloss:  1.20141056934\n",
      "Iter  189 \tloss:  1.20368416525\n",
      "Iter  190 \tloss:  1.20598671501\n",
      "Iter  191 \tloss:  1.2083186319\n",
      "Iter  192 \tloss:  1.21068033793\n",
      "Iter  193 \tloss:  1.21307226401\n",
      "Iter  194 \tloss:  1.21549485018\n",
      "Iter  195 \tloss:  1.21794854581\n",
      "Iter  196 \tloss:  1.22043380983\n",
      "Iter  197 \tloss:  1.22295111099\n",
      "Iter  198 \tloss:  1.22550092806\n",
      "Iter  199 \tloss:  1.22808375012\n"
     ]
    }
   ],
   "source": [
    "num_features = 10\n",
    "lamda_U = 0.1\n",
    "lamda_V = 0.1\n",
    "learning_rate = 0.00001\n",
    "momentum = 0.9\n",
    "\n",
    "U = np.random.rand(num_user, num_features)\n",
    "V = np.random.rand(num_mv, num_features)\n",
    "\n",
    "iter_num = 200\n",
    "loss_mom = []\n",
    "\n",
    "du_ = np.zeros((num_user, num_features))\n",
    "dv_ = np.zeros((num_mv, num_features))\n",
    "\n",
    "for k in range(iter_num):\n",
    "    predict_matrix = np.sum(U[aa_p,:]*V[aa_m,:], axis=1)\n",
    "    IO = np.array([predict_matrix-rating]).T\n",
    "\n",
    "    Ix_U = IO * V[aa_m,:] + lamda_U * U[aa_p,:]\n",
    "    Ix_V = IO * U[aa_p,:] + lamda_V * V[aa_m,:]\n",
    "    l = np.sum(np.square(IO)) + 1/2.0*lamda_U*np.sum(np.square(U)) + 1/2.0*lamda_V*np.sum(np.square(V))\n",
    "\n",
    "    l = math.sqrt(l/N)\n",
    "    \n",
    "    loss_mom.append(l)\n",
    "    \n",
    "    print \"Iter \" , k  , \"\\t\" + \"loss: \" , l\n",
    "    du = np.zeros((num_user, num_features))\n",
    "    dv = np.zeros((num_mv, num_features))\n",
    "    for i in range(N):\n",
    "        du[aa_p[i],:] = du[aa_p[i],:] + Ix_V[i,:]\n",
    "        dv[aa_m[i],:] = dv[aa_m[i],:] + Ix_U[i,:]\n",
    "        \n",
    "    dv = momentum * dv_ - learning_rate*dv\n",
    "    du = momentum * du_ - learning_rate*du\n",
    "    V = V + dv\n",
    "    U = U + du\n",
    "    \n",
    "    dv_ = dv\n",
    "    du_ = du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15728890>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f60fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0 \tloss:  1.66260796646\n",
      "Iter  1 \tloss:  1.60977879766\n",
      "Iter  2 \tloss:  1.57440262845\n",
      "Iter  3 \tloss:  1.54658897357\n",
      "Iter  4 \tloss:  1.52323920093\n",
      "Iter  5 \tloss:  1.50293083943\n",
      "Iter  6 \tloss:  1.48486214569\n",
      "Iter  7 \tloss:  1.46853691169\n",
      "Iter  8 \tloss:  1.45361607172\n",
      "Iter  9 \tloss:  1.43985929304\n",
      "Iter  10 \tloss:  1.42708821759\n",
      "Iter  11 \tloss:  1.41516653485\n",
      "Iter  12 \tloss:  1.40398653077\n",
      "Iter  13 \tloss:  1.39346128138\n",
      "Iter  14 \tloss:  1.38351913658\n",
      "Iter  15 \tloss:  1.37410021576\n",
      "Iter  16 \tloss:  1.36515384501\n",
      "Iter  17 \tloss:  1.35663679837\n",
      "Iter  18 \tloss:  1.34851194906\n",
      "Iter  19 \tloss:  1.34074718374\n",
      "Iter  20 \tloss:  1.33331451086\n",
      "Iter  21 \tloss:  1.32618934437\n",
      "Iter  22 \tloss:  1.31934993163\n",
      "Iter  23 \tloss:  1.31277689798\n",
      "Iter  24 \tloss:  1.30645288424\n",
      "Iter  25 \tloss:  1.30036225698\n",
      "Iter  26 \tloss:  1.29449087513\n",
      "Iter  27 \tloss:  1.28882589966\n",
      "Iter  28 \tloss:  1.28335563546\n",
      "Iter  29 \tloss:  1.27806939758\n",
      "Iter  30 \tloss:  1.27295739602\n",
      "Iter  31 \tloss:  1.26801063571\n",
      "Iter  32 \tloss:  1.26322082914\n",
      "Iter  33 \tloss:  1.25858032036\n",
      "Iter  34 \tloss:  1.25408201879\n",
      "Iter  35 \tloss:  1.24971934174\n",
      "Iter  36 \tloss:  1.24548616432\n",
      "Iter  37 \tloss:  1.24137677568\n",
      "Iter  38 \tloss:  1.23738584074\n",
      "Iter  39 \tloss:  1.2335083664\n",
      "Iter  40 \tloss:  1.22973967178\n",
      "Iter  41 \tloss:  1.22607536169\n",
      "Iter  42 \tloss:  1.22251130305\n",
      "Iter  43 \tloss:  1.21904360375\n",
      "Iter  44 \tloss:  1.2156685937\n",
      "Iter  45 \tloss:  1.21238280781\n",
      "Iter  46 \tloss:  1.20918297053\n",
      "Iter  47 \tloss:  1.20606598197\n",
      "Iter  48 \tloss:  1.20302890526\n",
      "Iter  49 \tloss:  1.20006895504\n",
      "Iter  50 \tloss:  1.19718348699\n",
      "Iter  51 \tloss:  1.19436998829\n",
      "Iter  52 \tloss:  1.19162606887\n",
      "Iter  53 \tloss:  1.18894945335\n",
      "Iter  54 \tloss:  1.18633797372\n",
      "Iter  55 \tloss:  1.18378956255\n",
      "Iter  56 \tloss:  1.18130224676\n",
      "Iter  57 \tloss:  1.17887414183\n",
      "Iter  58 \tloss:  1.17650344655\n",
      "Iter  59 \tloss:  1.17418843804\n",
      "Iter  60 \tloss:  1.17192746726\n",
      "Iter  61 \tloss:  1.16971895474\n",
      "Iter  62 \tloss:  1.16756138672\n",
      "Iter  63 \tloss:  1.16545331147\n",
      "Iter  64 \tloss:  1.16339333595\n",
      "Iter  65 \tloss:  1.16138012261\n",
      "Iter  66 \tloss:  1.15941238652\n",
      "Iter  67 \tloss:  1.15748889258\n",
      "Iter  68 \tloss:  1.15560845299\n",
      "Iter  69 \tloss:  1.15376992483\n",
      "Iter  70 \tloss:  1.15197220785\n",
      "Iter  71 \tloss:  1.15021424238\n",
      "Iter  72 \tloss:  1.14849500729\n",
      "Iter  73 \tloss:  1.14681351823\n",
      "Iter  74 \tloss:  1.14516882585\n",
      "Iter  75 \tloss:  1.14356001415\n",
      "Iter  76 \tloss:  1.14198619897\n",
      "Iter  77 \tloss:  1.14044652653\n",
      "Iter  78 \tloss:  1.13894017206\n",
      "Iter  79 \tloss:  1.13746633854\n",
      "Iter  80 \tloss:  1.13602425543\n",
      "Iter  81 \tloss:  1.13461317754\n",
      "Iter  82 \tloss:  1.13323238399\n",
      "Iter  83 \tloss:  1.1318811771\n",
      "Iter  84 \tloss:  1.13055888149\n",
      "Iter  85 \tloss:  1.12926484309\n",
      "Iter  86 \tloss:  1.12799842833\n",
      "Iter  87 \tloss:  1.12675902326\n",
      "Iter  88 \tloss:  1.1255460328\n",
      "Iter  89 \tloss:  1.12435887995\n",
      "Iter  90 \tloss:  1.12319700512\n",
      "Iter  91 \tloss:  1.12205986544\n",
      "Iter  92 \tloss:  1.12094693411\n",
      "Iter  93 \tloss:  1.11985769979\n",
      "Iter  94 \tloss:  1.11879166603\n",
      "Iter  95 \tloss:  1.11774835069\n",
      "Iter  96 \tloss:  1.11672728545\n",
      "Iter  97 \tloss:  1.11572801526\n",
      "Iter  98 \tloss:  1.11475009786\n",
      "Iter  99 \tloss:  1.11379310338\n",
      "Iter  100 \tloss:  1.11285661382\n",
      "Iter  101 \tloss:  1.11194022267\n",
      "Iter  102 \tloss:  1.11104353451\n",
      "Iter  103 \tloss:  1.11016616459\n",
      "Iter  104 \tloss:  1.10930773851\n",
      "Iter  105 \tloss:  1.10846789181\n",
      "Iter  106 \tloss:  1.10764626969\n",
      "Iter  107 \tloss:  1.10684252663\n",
      "Iter  108 \tloss:  1.10605632612\n",
      "Iter  109 \tloss:  1.10528734033\n",
      "Iter  110 \tloss:  1.10453524985\n",
      "Iter  111 \tloss:  1.1037997434\n",
      "Iter  112 \tloss:  1.10308051757\n",
      "Iter  113 \tloss:  1.10237727657\n",
      "Iter  114 \tloss:  1.10168973197\n",
      "Iter  115 \tloss:  1.1010176025\n",
      "Iter  116 \tloss:  1.10036061379\n",
      "Iter  117 \tloss:  1.0997184982\n",
      "Iter  118 \tloss:  1.09909099456\n",
      "Iter  119 \tloss:  1.09847784801\n",
      "Iter  120 \tloss:  1.09787880978\n",
      "Iter  121 \tloss:  1.09729363706\n",
      "Iter  122 \tloss:  1.09672209273\n",
      "Iter  123 \tloss:  1.0961639453\n",
      "Iter  124 \tloss:  1.09561896866\n",
      "Iter  125 \tloss:  1.09508694196\n",
      "Iter  126 \tloss:  1.09456764943\n",
      "Iter  127 \tloss:  1.09406088029\n",
      "Iter  128 \tloss:  1.09356642855\n",
      "Iter  129 \tloss:  1.09308409289\n",
      "Iter  130 \tloss:  1.09261367652\n",
      "Iter  131 \tloss:  1.0921549871\n",
      "Iter  132 \tloss:  1.09170783655\n",
      "Iter  133 \tloss:  1.09127204097\n",
      "Iter  134 \tloss:  1.0908474205\n",
      "Iter  135 \tloss:  1.09043379925\n",
      "Iter  136 \tloss:  1.09003100516\n",
      "Iter  137 \tloss:  1.08963886988\n",
      "Iter  138 \tloss:  1.08925722871\n",
      "Iter  139 \tloss:  1.08888592048\n",
      "Iter  140 \tloss:  1.08852478746\n",
      "Iter  141 \tloss:  1.08817367526\n",
      "Iter  142 \tloss:  1.08783243276\n",
      "Iter  143 \tloss:  1.08750091201\n",
      "Iter  144 \tloss:  1.08717896814\n",
      "Iter  145 \tloss:  1.08686645931\n",
      "Iter  146 \tloss:  1.08656324659\n",
      "Iter  147 \tloss:  1.08626919391\n",
      "Iter  148 \tloss:  1.08598416801\n",
      "Iter  149 \tloss:  1.0857080383\n",
      "Iter  150 \tloss:  1.08544067688\n",
      "Iter  151 \tloss:  1.08518195838\n",
      "Iter  152 \tloss:  1.08493175998\n",
      "Iter  153 \tloss:  1.08468996128\n",
      "Iter  154 \tloss:  1.0844564443\n",
      "Iter  155 \tloss:  1.08423109336\n",
      "Iter  156 \tloss:  1.08401379507\n",
      "Iter  157 \tloss:  1.08380443825\n",
      "Iter  158 \tloss:  1.0836029139\n",
      "Iter  159 \tloss:  1.0834091151\n",
      "Iter  160 \tloss:  1.08322293701\n",
      "Iter  161 \tloss:  1.08304427681\n",
      "Iter  162 \tloss:  1.08287303363\n",
      "Iter  163 \tloss:  1.0827091085\n",
      "Iter  164 \tloss:  1.08255240436\n",
      "Iter  165 \tloss:  1.08240282594\n",
      "Iter  166 \tloss:  1.08226027979\n",
      "Iter  167 \tloss:  1.08212467418\n",
      "Iter  168 \tloss:  1.08199591909\n",
      "Iter  169 \tloss:  1.08187392616\n",
      "Iter  170 \tloss:  1.08175860866\n",
      "Iter  171 \tloss:  1.08164988146\n",
      "Iter  172 \tloss:  1.08154766097\n",
      "Iter  173 \tloss:  1.08145186512\n",
      "Iter  174 \tloss:  1.08136241333\n",
      "Iter  175 \tloss:  1.08127922647\n",
      "Iter  176 \tloss:  1.08120222684\n",
      "Iter  177 \tloss:  1.0811313381\n",
      "Iter  178 \tloss:  1.08106648529\n",
      "Iter  179 \tloss:  1.08100759478\n",
      "Iter  180 \tloss:  1.08095459422\n",
      "Iter  181 \tloss:  1.08090741256\n",
      "Iter  182 \tloss:  1.08086597997\n",
      "Iter  183 \tloss:  1.08083022783\n",
      "Iter  184 \tloss:  1.08080008875\n",
      "Iter  185 \tloss:  1.08077549646\n",
      "Iter  186 \tloss:  1.08075638586\n",
      "Iter  187 \tloss:  1.08074269295\n",
      "Iter  188 \tloss:  1.08073435484\n",
      "Iter  189 \tloss:  1.0807313097\n",
      "Iter  190 \tloss:  1.08073349675\n",
      "Iter  191 \tloss:  1.08074085624\n",
      "Iter  192 \tloss:  1.08075332941\n",
      "Iter  193 \tloss:  1.08077085851\n",
      "Iter  194 \tloss:  1.08079338673\n",
      "Iter  195 \tloss:  1.08082085822\n",
      "Iter  196 \tloss:  1.08085321805\n",
      "Iter  197 \tloss:  1.0808904122\n",
      "Iter  198 \tloss:  1.08093238754\n",
      "Iter  199 \tloss:  1.0809790918\n"
     ]
    }
   ],
   "source": [
    "num_features = 10\n",
    "lamda_U = 0.1\n",
    "lamda_V = 0.1\n",
    "learning_rate = 0.01\n",
    "\n",
    "U = np.random.rand(num_user, num_features)\n",
    "V = np.random.rand(num_mv, num_features)\n",
    "\n",
    "iter_num = 200\n",
    "loss_ada = []\n",
    "\n",
    "grad_u_sum = np.zeros((num_user, num_features)) + 0.0001\n",
    "grad_v_sum = np.zeros((num_mv, num_features)) + 0.0001\n",
    "\n",
    "for k in range(iter_num):\n",
    "    predict_matrix = np.sum(U[aa_p,:]*V[aa_m,:], axis=1)\n",
    "    IO = np.array([predict_matrix-rating]).T\n",
    "\n",
    "    Ix_U = IO * V[aa_m,:] + lamda_U * U[aa_p,:]\n",
    "    Ix_V = IO * U[aa_p,:] + lamda_V * V[aa_m,:]\n",
    "    l = np.sum(np.square(IO)) + 1/2.0*lamda_U*np.sum(np.square(U)) + 1/2.0*lamda_V*np.sum(np.square(V))\n",
    "\n",
    "    l = math.sqrt(l/N)\n",
    "    \n",
    "    loss_ada.append(l)\n",
    "    \n",
    "    print \"Iter \" , k  , \"\\t\" + \"loss: \" , l\n",
    "    du = np.zeros((num_user, num_features))\n",
    "    dv = np.zeros((num_mv, num_features))\n",
    "    for i in range(N):\n",
    "        du[aa_p[i],:] = du[aa_p[i],:] + Ix_V[i,:]\n",
    "        dv[aa_m[i],:] = dv[aa_m[i],:] + Ix_U[i,:]\n",
    "    \n",
    "    grad_u_sum += np.square(du)\n",
    "    grad_v_sum += np.square(dv)\n",
    "    \n",
    "    dv = -1.0 / np.sqrt(grad_v_sum) * learning_rate*dv\n",
    "    du = -1.0 / np.sqrt(grad_u_sum) * learning_rate*du\n",
    "    V = V + dv\n",
    "    U = U + du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x158b5bf0>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117d3fb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
