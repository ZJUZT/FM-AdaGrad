{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD for FM\n",
    "目标函数\n",
    "![](img_fm/1.png)\n",
    "加入正则项，防止过拟合\n",
    "![](img_fm/2.png)\n",
    "Algorithm for SGD\n",
    "![](img_fm/3.png)\n",
    "![](img_fm/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> numpy's dot function does not have native support for handling sparse matrices. What is happening is numpy thinks of the sparse matrix C as a python object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Read in data\n",
    "def loadData(filename,path=\"ml-100k/\"):\n",
    "    data = []\n",
    "    y = []\n",
    "    users=set()\n",
    "    items=set()\n",
    "    with open(path+filename) as f:\n",
    "        for line in f:\n",
    "            (user,movieid,rating,ts)=line.split('\\t')\n",
    "            data.append({ \"user_id\": str(user), \"movie_id\": str(movieid)})\n",
    "            y.append(float(rating))\n",
    "            users.add(user)\n",
    "            items.add(movieid)\n",
    "\n",
    "    return (data, np.array(y), users, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用SGD训练FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FM_SGD():\n",
    "    \n",
    "    def __init__(self,\n",
    "                iter_num,\n",
    "                learning_rate,\n",
    "                factors_num,\n",
    "                reg,\n",
    "                verbose = True):\n",
    "        \n",
    "        # 迭代次数\n",
    "        self.iter_num = iter_num\n",
    "        \n",
    "        #学习速率\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # 分解器feature个数\n",
    "        self.factors_num = factors_num\n",
    "        \n",
    "        # lambda\n",
    "        self.reg = reg\n",
    "        \n",
    "        # 输出执行信息\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # global bias\n",
    "        self.w0 = 0;\n",
    "        \n",
    "        # feature bias\n",
    "        self.W = 0;\n",
    "        \n",
    "        # feature\n",
    "        self.V = 0;\n",
    "        \n",
    "        # 训练过程中的mse\n",
    "        self.mse = []\n",
    "        \n",
    "        # target y的最大值与最小值，for prune\n",
    "        self.y_max = 0.0;\n",
    "        self.y_min = 0.0;\n",
    "        \n",
    "        \n",
    "    def train(self, X_, y_):\n",
    "        \n",
    "        (n,p) = X_.shape\n",
    "        \n",
    "        self.mse = []\n",
    "        \n",
    "        # global bias\n",
    "        self.w0 = sum(np.random.rand(1))  # bias\n",
    "        \n",
    "        # feature bias\n",
    "        self.W = 1e-5*np.random.rand(1,p)\n",
    "        \n",
    "        # feature\n",
    "        self.V = 1e-5*np.random.rand(p,self.factors_num)\n",
    "        \n",
    "        self.y_max = np.max(y_)\n",
    "        self.y_min = np.min(y_)\n",
    "        \n",
    "        for j in xrange(self.iter_num):\n",
    "            \n",
    "            loss_sgd = []\n",
    "\n",
    "            # shuffle\n",
    "            reidx = np.random.permutation(n)\n",
    "            X_train = X_[reidx,:]\n",
    "            y_train = y_[reidx]\n",
    "\n",
    "            \n",
    "\n",
    "            for i in xrange(n):\n",
    "\n",
    "                if self.verbose and i%1000 ==0:\n",
    "                    print 'prossing ' + str(i) + 'th sample...'\n",
    "\n",
    "                X = X_train[i,:]\n",
    "                y = y_train[i]\n",
    "\n",
    "                # too slow\n",
    "            #     y_predict = (w0 + W*X.T + ((X.T*X).multiply((np.triu(V.dot(V.T),1)))).sum().sum())[0,0]\n",
    "\n",
    "                tmp = np.sum(X.T.multiply(self.V),axis=0)\n",
    "                factor_part = (np.sum(np.multiply(tmp,tmp)) - np.sum((X.T.multiply(X.T)).multiply(np.multiply(self.V,self.V))))/2\n",
    "                y_predict = self.w0 + np.sum(self.W*X.T) + factor_part\n",
    "                \n",
    "#                 print y_predict\n",
    "\n",
    "                # prune\n",
    "                if y_predict < self.y_min:\n",
    "                    y_predict = self.y_min\n",
    "\n",
    "                if y_predict > self.y_max:\n",
    "                    y_predict = self.y_max\n",
    "\n",
    "                diff = y_predict-y\n",
    "                loss_sgd.append(math.pow(diff,2))\n",
    "\n",
    "                # update mse\n",
    "                self.mse.append(sum(loss_sgd)/len(loss_sgd))\n",
    "\n",
    "                # update w0\n",
    "                self.w0 = self.w0 - learning_rate*2*diff * (1)\n",
    "                \n",
    "                # update W\n",
    "                self.W = self.W - learning_rate*2*diff * (X)\n",
    "                \n",
    "                # update V\n",
    "                self.V = self.V - learning_rate * 2*diff* (X.T.multiply((np.tile(X*self.V,(p,1)) - X.T.multiply(self.V))))\n",
    "\n",
    "    def validate(self, X_, y_):\n",
    "        (n,p) = X_.shape\n",
    "        \n",
    "        mse = []\n",
    "        \n",
    "\n",
    "        for i in xrange(n):\n",
    "\n",
    "            if self.verbose and i%1000 ==0:\n",
    "                print 'prossing ' + str(i) + 'th sample...'\n",
    "\n",
    "            X = X_train[i,:]\n",
    "            y = y_train[i]\n",
    "\n",
    "            # too slow\n",
    "        #     y_predict = (w0 + W*X.T + ((X.T*X).multiply((np.triu(V.dot(V.T),1)))).sum().sum())[0,0]\n",
    "\n",
    "            tmp = np.sum(X.T.multiply(self.V),axis=0)\n",
    "            factor_part = (np.sum(np.multiply(tmp,tmp)) - np.sum((X.T.multiply(X.T)).multiply(np.multiply(self.V,self.V))))/2\n",
    "            y_predict = self.w0 + np.sum(self.W*X.T) + factor_part\n",
    "\n",
    "#                 print y_predict\n",
    "\n",
    "            # prune\n",
    "            if y_predict < self.y_min:\n",
    "                y_predict = self.y_min\n",
    "\n",
    "            if y_predict > self.y_max:\n",
    "                y_predict = self.y_max\n",
    "\n",
    "            diff = y_predict-y\n",
    "            loss_sgd.append(math.pow(diff,2))\n",
    "\n",
    "            # update mse\n",
    "            mse.append(sum(loss_sgd)/len(loss_sgd))\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prossing 0th sample...\n",
      "prossing 1000th sample...\n",
      "prossing 2000th sample...\n",
      "prossing 3000th sample...\n",
      "prossing 4000th sample...\n",
      "prossing 5000th sample...\n",
      "prossing 6000th sample...\n",
      "prossing 7000th sample...\n",
      "prossing 8000th sample...\n",
      "prossing 9000th sample...\n",
      "prossing 10000th sample...\n",
      "prossing 11000th sample...\n",
      "prossing 12000th sample...\n",
      "prossing 13000th sample...\n",
      "prossing 14000th sample...\n",
      "prossing 15000th sample...\n",
      "prossing 16000th sample...\n",
      "prossing 17000th sample...\n",
      "prossing 18000th sample...\n",
      "prossing 19000th sample...\n",
      "prossing 20000th sample...\n",
      "prossing 21000th sample...\n",
      "prossing 22000th sample...\n",
      "prossing 23000th sample...\n",
      "prossing 24000th sample...\n",
      "prossing 25000th sample...\n",
      "prossing 26000th sample...\n",
      "prossing 27000th sample...\n",
      "prossing 28000th sample...\n",
      "prossing 29000th sample...\n",
      "prossing 30000th sample...\n",
      "prossing 31000th sample...\n",
      "prossing 32000th sample...\n",
      "prossing 33000th sample...\n",
      "prossing 34000th sample...\n",
      "prossing 35000th sample...\n",
      "prossing 36000th sample...\n",
      "prossing 37000th sample...\n",
      "prossing 38000th sample...\n",
      "prossing 39000th sample...\n",
      "prossing 40000th sample...\n",
      "prossing 41000th sample...\n",
      "prossing 42000th sample...\n",
      "prossing 43000th sample...\n",
      "prossing 44000th sample...\n",
      "prossing 45000th sample...\n",
      "prossing 46000th sample...\n",
      "prossing 47000th sample...\n",
      "prossing 48000th sample...\n",
      "prossing 49000th sample...\n",
      "prossing 50000th sample...\n",
      "prossing 51000th sample...\n",
      "prossing 52000th sample...\n",
      "prossing 53000th sample...\n",
      "prossing 54000th sample...\n",
      "prossing 55000th sample...\n",
      "prossing 56000th sample...\n",
      "prossing 57000th sample...\n",
      "prossing 58000th sample...\n",
      "prossing 59000th sample...\n",
      "prossing 60000th sample...\n",
      "prossing 61000th sample...\n",
      "prossing 62000th sample...\n",
      "prossing 63000th sample...\n",
      "prossing 64000th sample...\n",
      "prossing 65000th sample...\n",
      "prossing 66000th sample...\n",
      "prossing 67000th sample...\n",
      "prossing 68000th sample...\n",
      "prossing 69000th sample...\n",
      "prossing 70000th sample...\n",
      "prossing 71000th sample...\n",
      "prossing 72000th sample...\n",
      "prossing 73000th sample...\n",
      "prossing 74000th sample...\n",
      "prossing 75000th sample...\n",
      "prossing 76000th sample...\n",
      "prossing 77000th sample...\n",
      "prossing 78000th sample...\n",
      "prossing 79000th sample...\n",
      "prossing 80000th sample...\n",
      "prossing 81000th sample...\n",
      "prossing 82000th sample...\n",
      "prossing 83000th sample...\n",
      "prossing 84000th sample...\n",
      "prossing 85000th sample...\n",
      "prossing 86000th sample...\n",
      "prossing 87000th sample...\n",
      "prossing 88000th sample...\n",
      "prossing 89000th sample...\n",
      "prossing 90000th sample...\n"
     ]
    }
   ],
   "source": [
    "(train_data, y_train, train_users, train_items) = loadData(\"ua.base\")\n",
    "(test_data, y_test, test_users, test_items) = loadData(\"ua.test\")\n",
    "\n",
    "v = DictVectorizer()\n",
    "X_train = v.fit_transform(train_data)\n",
    "X_test = v.transform(test_data)\n",
    "fm_sgd = FM_SGD(iter_num=1,\n",
    "               learning_rate=0.01,\n",
    "               factors_num=10,\n",
    "               reg=0.1)\n",
    "fm_sgd.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x34507e70>]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAFwCAYAAAD5dZn+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x36ed2dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15,6\n",
    "plt.grid(True)\n",
    "plt.plot(fm_sgd.mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prossing 0th sample...\n"
     ]
    }
   ],
   "source": [
    "mse = fm_sgd.validate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
